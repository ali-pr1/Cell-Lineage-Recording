from sklearn.manifold import TSNE
from scipy.spatial import distance
import seaborn as sns
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt


df = pd.read_excel ('E:\\ALI\\processing project\\Zombie\\dil 1\\Analysis\\pos1\\{:02d}\\'.format(p)+'_pos{:02d}dy1.xlsx'.format(p))
df1 = pd.read_excel ('E:\\ALI\\processing project\\Zombie\\dil 1\\Analysis\\pos1\\{:02d}\\'.format(p)+'_pos{:02d}dy2.xlsx'.format(p))
df2 = pd.read_excel ('E:\\ALI\\processing project\\Zombie\\dil 1\\Analysis\\pos1\\{:02d}\\'.format(p)+'_pos{:02d}st.xlsx'.format(p))
hyb_num=18
df.drop(columns='Unnamed: 0',inplace=True)
df.drop(columns='inf',inplace=True)
df1.drop(columns='inf',inplace=True)
df2.drop(columns='inf',inplace=True)
df1.drop(columns='Unnamed: 0',inplace=True)
df2.drop(columns='Unnamed: 0',inplace=True)
lst=df['647']
## converting values in a logarithmic scale
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df['647']=lst
lst=df['555']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df['555']=lst
lst=df1['488']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df1['488']=lst
lst=df1['594']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df1['594']=lst
lst=df2['647']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df2['647']=lst
lst=df2['555']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df2['555']=lst
lst=df2['488']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df2['488']=lst
lst=df2['594']
for i in range(len(lst)):
    lst[i]=np.log(lst[i])
df2['594']=lst


dfa=pd.DataFrame()
dfa['647']=df['647']
dfa['555']=df['555']

# in dynamic barcodes main dimension is two so I reduced it to 1
#cosine metric
tsne = TSNE(n_components=1,metric=distance.cosine)

tsne_results = tsne.fit_transform(dfa)
#cluster into two based on tsne values
kmeans = KMeans(n_clusters=2,n_init=20, max_iter=1000).fit(tsne_results)
df['label']=list(kmeans.labels_)

## plot to see how clustering worked out
plt.figure(figsize=(16,10))
sns.scatterplot(
    x="647",y='555',
    hue="label",
    palette=['green','red'],
    data=df,
    legend="full",
    alpha=0.3
)

# compare mean log intensities to see how clustering worked
print(np.mean(df[df['label']==0]['647']))
print(np.mean(df[df['label']==0]['555']))
print(np.mean(df[df['label']==1]['647']))
print(np.mean(df[df['label']==1]['555']))

#do the same for other channels

dfa=pd.DataFrame()
dfa['488']=df1['488']
dfa['594']=df1['594']
tsne = TSNE(n_components=1,metric=distance.cosine)

tsne_results = tsne.fit_transform(dfa)
# I did try other components for Kmeans clustering but it did not change much
kmeans = KMeans(n_clusters=2,n_init=20, max_iter=1000).fit(tsne_results)
df1['label']=list(kmeans.labels_)

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="488",y='594',
    hue="label",
    palette=['green','red'],
    data=df1,
    legend="full",
    alpha=0.3
)

#for static barcode we have dimension of 4
## I reduced it to 1 and 2 using tsne
# 2 was better

dfa=pd.DataFrame()
dfa['647']=df2['647']
dfa['488']=df2['488']
dfa['555']=df2['555']
dfa['594']=df2['594']
tsne = TSNE(n_components=2,metric=distance.cosine)
tsne_results = tsne.fit_transform(dfa)
dfa['tsne-2d-one'] = tsne_results[:,0]
dfa['tsne-2d-two'] = tsne_results[:,1]
kmeans = KMeans(n_clusters=4).fit(tsne_results)
df2['label']=list(kmeans.labels_)
df2

# I do not have luxury of plotting so I used mean
print(np.mean(df2[df2['label']==0]['647']))
print(np.mean(df2[df2['label']==0]['488']))
print(np.mean(df2[df2['label']==0]['555']))
print(np.mean(df2[df2['label']==0]['594']))
print(np.mean(df2[df2['label']==1]['647']))
print(np.mean(df2[df2['label']==1]['488']))
print(np.mean(df2[df2['label']==1]['555']))
print(np.mean(df2[df2['label']==1]['594']))
print(np.mean(df2[df2['label']==2]['647']))
print(np.mean(df2[df2['label']==2]['488']))
print(np.mean(df2[df2['label']==2]['555']))
print(np.mean(df2[df2['label']==2]['594']))
print(np.mean(df2[df2['label']==3]['647']))
print(np.mean(df2[df2['label']==3]['488']))
print(np.mean(df2[df2['label']==3]['555']))
print(np.mean(df2[df2['label']==3]['594']))


#questions:
#how can I evaluate the clustring?
#any points for improvment?
#do you find 647-555 clustring of this example valid(look at mean values)?
#if there's problem could it because of previous state(seperating activesites)?
# is it necessary to identify each cluster represents what biological observation or I can use abstract symbols now on?
# I used another form of clusteriting, it appears kmeans can do so much better
